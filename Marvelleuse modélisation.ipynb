{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des textes et premières observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"base.csv\", sep=\"\\t\", encoding=\"latin-1\", index_col=0)\n",
    "data.drop([\"Fichier\", \"Longueur\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res=[]\n",
    "for i in range (len(data)) :\n",
    "    if data[\"Note\"][i] >7 :\n",
    "        res.append(1)\n",
    "    else : \n",
    "        res.append(0)\n",
    "data[\"Note\"]=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=data.iloc[np.random.permutation(len(data))]\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avis</th>\n",
       "      <th>Film</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dans la surenchère de super-héros qui est aujo...</td>\n",
       "      <td>XD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il n'y a que chez les super-héros qu'on peut f...</td>\n",
       "      <td>Sb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C'est une «chanson» qui s'inculque. Qui se déc...</td>\n",
       "      <td>GG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spider-Man est un héros de l'univers Marvel, I...</td>\n",
       "      <td>SM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le sucre est un poison pour la santé, mais il ...</td>\n",
       "      <td>AU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Avis Film  Note\n",
       "0  Dans la surenchère de super-héros qui est aujo...   XD     1\n",
       "1  Il n'y a que chez les super-héros qu'on peut f...   Sb     1\n",
       "2  C'est une «chanson» qui s'inculque. Qui se déc...   GG     1\n",
       "3  Spider-Man est un héros de l'univers Marvel, I...   SM     1\n",
       "4  Le sucre est un poison pour la santé, mais il ...   AU     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation entre train et test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limite=int(len(data)*2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train=data[\"Avis\"][:limite]\n",
    "data_test=data[\"Avis\"][limite:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=data[\"Note\"][:limite]\n",
    "y_test=data[\"Note\"][limite:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# chargement des stopwords français\n",
    "stopwords_extent= stopwords.words('french')+[\",\", \".\", \"(\", \")\", \"c'est\", \"le\", \"la\", \"les\", \"un\", \"une\", \"des\", \"c'est\",\n",
    "                                             \"va\", \"ainsi\", \"ce\", \"cette\", \"ces\", \"là\", \"du\", \"s\", \"''\", ':', \"a\"\n",
    "                                            'cependant', 'certain', 'certaine', 'certainement', 'certaines', 'certains', \n",
    "                                             'certes', 'cet', 'ceux', 'chacun', 'chaque']\n",
    "#retire certains signes de ponctuation qui ne présentent pas\n",
    "#d'intérêt dans l'immédiat.\n",
    "\n",
    "french_stopwords = set(stopwords_extent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(max) :\n",
    "    count_vect = CountVectorizer(min_df=0.0, stop_words=french_stopwords, max_features=max)\n",
    "    X_train_counts = count_vect.fit_transform(data_train)\n",
    "    \n",
    "    tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "    X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "    \n",
    "    clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "\n",
    "    docs_new = data_test\n",
    "    X_new_counts = count_vect.transform(docs_new)\n",
    "    X_new_tf = tf_transformer.transform(X_new_counts)\n",
    "    predicted = clf.predict(X_new_tf)\n",
    "\n",
    "    return np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100, 0.67142857142857137], [200, 0.70952380952380956], [400, 0.76190476190476186], [600, 0.75714285714285712], [800, 0.76666666666666672], [1000, 0.77619047619047621], [3000, 0.68571428571428572], [5000, 0.59999999999999998], [6000, 0.59999999999999998], [10000, 0.56190476190476191]]\n"
     ]
    }
   ],
   "source": [
    "print([[i, score(i)] for i in [100, 200, 400, 600, 800, 1000, 3000, 5000, 6000, 10000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77619047619047621"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df=0.0, stop_words=french_stopwords, max_features=1000)\n",
    "X_train_counts = count_vect.fit_transform(data_train)\n",
    "    \n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "    \n",
    "clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "\n",
    "docs_new = data_test\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tf = tf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tf)\n",
    "\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75714285714285712"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df=0.0, stop_words=french_stopwords, max_features=1000, ngram_range=(1, 2))\n",
    "X_train_counts = count_vect.fit_transform(data_train)\n",
    "    \n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "    \n",
    "clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "\n",
    "docs_new = data_test\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tf = tf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tf)\n",
    "\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Idées pour améliorer le score : \n",
    "- scrapper plus de données,\n",
    "- jeter un coup d'oeil sur les features et en retirer (soit par intuition, regard sur les données(ajouter des stopwords), soit en jouant sur max_features dans countvectorizer),\n",
    "- essayer d'autres modèles : linéaires, arbres de décision (avec un nombre minimal d'ind par feuille)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74285714285714288"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df=0.0, stop_words=french_stopwords, max_features=1000, ngram_range=(2,2))\n",
    "X_train_counts = count_vect.fit_transform(data_train)\n",
    "    \n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "    \n",
    "clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "\n",
    "docs_new = data_test\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tf = tf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tf)\n",
    "\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6333333333333333"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df=0.0, stop_words=french_stopwords, max_features=1000, ngram_range=(3,3))\n",
    "X_train_counts = count_vect.fit_transform(data_train)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train_tf_lin = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "\n",
    "clf_lin = LinearSVC().fit(X_train_tf_lin, y_train)\n",
    "\n",
    "docs_new = data_test\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tf = tf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted_lin = clf_lin.predict(X_new_tf)\n",
    "\n",
    "np.mean(predicted_lin == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "http://streamhacker.com/2012/11/22/text-classification-sentiment-analysis-nltk-scikitlearn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coeff_cr=clf.coef_.argsort()[0]\n",
    "coeff_dec=clf.coef_.argsort()[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeff :-0.186388722533 pour :spider man\n",
      "coeff :-0.574879460811 pour :super héros\n",
      "coeff :0.226398578216 pour :iron man\n",
      "coeff :0.206366367018 pour :captain america\n",
      "coeff :0.37432297347 pour :sam raimi\n",
      "coeff :0.0292976837649 pour :peter parker\n",
      "coeff :-0.0154127364728 pour :effets spéciaux\n",
      "coeff :-0.337683119775 pour :très bon\n",
      "coeff :0.88526016418 pour :très bien\n",
      "coeff :-0.211933862962 pour :film super\n",
      "coeff :0.688429192536 pour :scènes action\n",
      "coeff :0.24287947928 pour :films super\n",
      "coeff :0.687878932005 pour :bouffon vert\n",
      "coeff :0.148286137749 pour :soldat hiver\n",
      "coeff :-0.404322715881 pour :bryan singer\n",
      "coeff :0.930454737326 pour :bon film\n",
      "coeff :-0.502185279111 pour :first class\n",
      "coeff :0.216952034944 pour :tony stark\n",
      "coeff :0.329600869003 pour :mary jane\n",
      "coeff :-0.7219312654 pour :premier film\n",
      "coeff :0.444499238084 pour :downey jr\n",
      "coeff :0.0138125194145 pour :robert downey\n",
      "coeff :-0.374186204946 pour :gardiens galaxie\n",
      "coeff :0.0616152051193 pour :tobey maguire\n",
      "coeff :0.434650394441 pour :peut être\n",
      "coeff :-0.108746471543 pour :premier volet\n",
      "coeff :-0.0370965760271 pour :mise scène\n",
      "coeff :0.314296293645 pour :scènes actions\n",
      "coeff :0.243340967324 pour :civil war\n",
      "coeff :-0.211115722831 pour :joss whedon\n",
      "coeff :0.355656474438 pour :long métrage\n",
      "coeff :0.312088472236 pour :charles xavier\n",
      "coeff :0.167733785247 pour :entre deux\n",
      "coeff :0.335976583996 pour :peu plus\n",
      "coeff :0.367899214236 pour :premier opus\n",
      "coeff :0.559316936142 pour :toujours aussi\n",
      "coeff :0.0383700835741 pour :tout long\n",
      "coeff :-0.0532212061698 pour :doctor strange\n",
      "coeff :0.0545567710529 pour :tout monde\n",
      "coeff :-0.0869433289312 pour :tout simplement\n",
      "coeff :0.294147680602 pour :sans doute\n",
      "coeff :0.245100630287 pour :steve rogers\n",
      "coeff :-0.268008387276 pour :univers marvel\n",
      "coeff :0.320609616423 pour :days of\n",
      "coeff :0.506779204463 pour :très bonne\n",
      "coeff :1.15324144868 pour :très bons\n",
      "coeff :0.0916541630855 pour :future past\n",
      "coeff :-0.368267278217 pour :marvel studios\n",
      "coeff :-0.346758800961 pour :meilleur film\n",
      "coeff :0.115602427357 pour :hugh jackman\n"
     ]
    }
   ],
   "source": [
    "for i in range (50) :\n",
    "    print(\"coeff :\"+ str(clf_lin.coef_[0][coeff_dec[i]])+\" pour :\"+count_vect.get_feature_names()[coeff_dec[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeff :-0.114303193949 pour :ça suffit\n",
      "coeff :-0.059963044104 pour :trois fois\n",
      "coeff :-0.0313714316869 pour :mal écrit\n",
      "coeff :0.1647771063 pour :christian chat\n",
      "coeff :-0.0161444152248 pour :demande si\n",
      "coeff :0.213643308907 pour :guerre contre\n",
      "coeff :0.519254493305 pour :chat parle\n",
      "coeff :-0.335478786675 pour :tante milf\n",
      "coeff :-0.58967719617 pour :ça part\n",
      "coeff :-0.0496227079574 pour :encore moins\n",
      "coeff :-0.556740893816 pour :trilogie raimi\n",
      "coeff :0.361263656391 pour :peyton reed\n",
      "coeff :-0.660269402961 pour :aucun intérêt\n",
      "coeff :-0.708067484114 pour :pete ouais\n",
      "coeff :0.194658269456 pour :ça veut\n",
      "coeff :0.335293341231 pour :liv tyler\n",
      "coeff :-0.260550380729 pour :marvel universe\n",
      "coeff :-0.22039363023 pour :ça tante\n",
      "coeff :-0.275858620499 pour :paul rudd\n",
      "coeff :0.106802240096 pour :zack snyder\n",
      "coeff :0.108721226912 pour :petit peu\n",
      "coeff :0.219751249927 pour :encore ça\n",
      "coeff :-0.486928891273 pour :parce faut\n",
      "coeff :0.394020852467 pour :seule seconde\n",
      "coeff :0.194159113492 pour :bon ça\n",
      "coeff :-0.529610600856 pour :michael douglas\n",
      "coeff :0.777872751006 pour :absolument rien\n",
      "coeff :0.0787280864467 pour :comics civil\n",
      "coeff :0.0612120730277 pour :parce ça\n",
      "coeff :-0.57694342657 pour :ça faisait\n",
      "coeff :0.499340221517 pour :tom holland\n",
      "coeff :0.174693259024 pour :très mauvais\n",
      "coeff :-0.36649320964 pour :lee jones\n",
      "coeff :-0.0010743594896 pour :tommy lee\n",
      "coeff :-0.110196815115 pour :mauvais film\n",
      "coeff :-0.102154727315 pour :ça devient\n",
      "coeff :0.820518199311 pour :emma stone\n",
      "coeff :-0.270706164668 pour :ça peut\n",
      "coeff :0.412560314697 pour :dessus tête\n",
      "coeff :-0.253931362715 pour :ça être\n",
      "coeff :-0.271067604645 pour :yes man\n",
      "coeff :-0.142864000971 pour :reste bien\n",
      "coeff :-0.3392140422 pour :james horner\n",
      "coeff :0.758514699729 pour :peut plus\n",
      "coeff :-0.0203199739995 pour :trop mal\n",
      "coeff :-0.14105983165 pour :fait deux\n",
      "coeff :-0.491746684539 pour :pendant tout\n",
      "coeff :-0.635491645772 pour :minutes film\n",
      "coeff :-0.693668196842 pour :www senscritique\n",
      "coeff :0.205841197747 pour :senscritique com\n"
     ]
    }
   ],
   "source": [
    "for i in range (50) :\n",
    "    print(\"coeff :\"+ str(clf_lin.coef_[0][coeff_cr[i]])+\" pour :\"+count_vect.get_feature_names()[coeff_cr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
